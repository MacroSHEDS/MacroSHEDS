---
title: MacroSheds data retrieval and flux calculation 
author: Weston Slaughter, Spencer Rhea, Mike Vlah
subtitle: Using the `macrosheds` package to retrieve discharge and chemistry data for target sites and variables, and to calculate simple stream solute flux
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{MacroSheds data retrieval and flux calculation}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

_See https://eartharxiv.org/repository/view/3499/ for background_

This walkthrough is from the perspective of a first time user, with some knowledge of the R programming language. This example user, for a college project, needs to compare the flux of nitrate between two watersheds, one from the Eastern US and one from the Western US, each with at least 60 years of data.

You can use [macrosheds.org](https://macrosheds.org) to explore the full dataset, and to identify sites that
fit your needs.


# Install and explore the `macrosheds` package


To use the `macrosheds` package, you must first **make sure you have the `macrosheds` package on your computer, built, and installed in R**. Currently, the package is only available via github. If you have not already, you can install the `macrosheds` package as follows: 

```{r ms-install, eval = FALSE}
# install.packages('devtools') #you may need to install devtools too

devtools::install_github('https://github.com/MacroSHEDS/macrosheds')
```

Now load the package. We're loading ggplot2 here as well, but you don't need it to use `macrosheds`.

```{r setup-library, message = FALSE}
   
library(macrosheds)
library(ggplot2)

```

Explore package functions with `help()`

```{r ms-help}
help(package = macrosheds)
```


# Identify target sites and variables in the MacroSheds dataset


Our first goal is to **identify sites we might want to pull data from**. To get more information about MacroSheds sites, we will use the function `ms_load_sites`, which loads a tibble of MacroSheds site metadata. 


#### ms\_load\_sites


```{r ms-site-data}
?ms_load_sites
```


```{r ms-sites}
ms_sites <- ms_load_sites()
colnames(ms_sites)
```

Skip the rest of this subsection if you just want to see demonstrations of `macrosheds` functions.

Our objective is to find 2 watersheds, one in the Eastern US and one in the Western US, which both have at least 60 years of nitrate data. You can use [macrosheds.org](https://macrosheds.org) for this, too.

The `ms_sites` `data.frame` columns include "latitude", "longitude", "first\_record\_utc", and "last\_record\_utc". Let's use these to see what sites meet our needs.


```{r ms-site-filter}
# calculate the approximate number of days in sixty years
sixty_yrs_days <- 365 * 60

# filter the dataframe of macrosheds sites
target_sites <- ms_sites %>%
    # to make sure our sites are roughly western or eastern 
    filter(longitude > -95 | longitude < -115) %>%
    mutate(period = as.numeric(
        difftime(last_record_utc,
                 first_record_utc,
                 units = 'days'
                 ))) %>%
    # to get records > 60 years
    filter(period > sixty_yrs_days)

# let's list the unique sites left after our filtering
unique(target_sites$domain)
head(target_sites)
  
# and calculate summary statistics on these sites, to help
# choose which sites have the best data for our needs
target_summary <- target_sites %>%
    group_by(domain) %>%
    summarize(
        mean_long = mean(longitude),
        sum_obs = sum(n_observations),
        min_date = min(first_record_utc),
        max_date = min(last_record_utc)
    )
  
head(target_summary)
```

By filtering the site metadata, we have found three domains that meet our requirements. Two of these sites are in the Northeastern US (Fernow, HBEF) and one is on the West Coast (HJ Andrews). See the map at [macrosheds.org](https://macrosheds.org). Our summary data show that HBEF has a greater number of overall observations, so let's go with that and HJ Andrews.

```{r}
my_domains <- c('hbef', 'hjandrews')
```

#### ms\_load\_variables

Now, we should choose the best site from HBEF and the best site from HJ Andrews. Let's go with the one from each domain that has the most complete nitrate record.


```{r ms-vars}
ms_vars <- ms_load_variables(var_set = 'timeseries')
head(ms_vars)
```


```{r ms-vars-filter}
filter(ms_vars, grepl('nitrate', variable_name, ignore.case = TRUE))

# Nitrate-N of stream water has the most observations. The variable_code
# for that is 'NO3_N'. Let's see if our sites have that variable.

ms_sitevar_catalog <- ms_load_variables(var_set = 'timeseries_by_site')
ms_sitevar_catalog %>% 
    filter(domain %in% my_domains,
           variable_code == 'NO3_N',
           chem_category == 'stream_conc'
           ) %>% 
    arrange(desc(mean_obs_per_day), desc(observations))

#it looks like GSWS07 comes out on top for HJ Andrews, and w7 for HBEF.
```



# Retrieve discharge data for target sites


Now, we will retrieve the target data: discharge and nitrate for our two sites. First, choose a directory to save the data to, and create a vector of target domain names. 

``` {r ms-dir}
my_ms_dir <- './example/data'
```


##### ms\_download\_core\_data


```{r}
?ms_download_core_data
```

Now, we retrieve MacroSheds data by domain and save it to our new `macrosheds_root` directory.
This same directory should be used when downloading watershed attribute data via `ms_download_ws_attr`,
and it _must_ be used to load data via `ms_load_product`. You can download all core data
with `domains = 'all'`

``` {r ms-data, eval = TRUE}
options(timeout = 600) #default 60 might not be enough if your connection is slow

ms_download_core_data(
    macrosheds_root = my_ms_dir,
    domains = my_domains,
    quiet = TRUE
)
```


##### ms\_load\_product    *discharge*


Now we have the data downloaded, but we want to load specific variables into the R session. To do this, we use `ms_load_product`. 

```{r ms-load}
?ms_load_product
```

Pointing to the directory we downloaded the data to, we use this function to pull out discharge data for two sites.

```{r ms-q}
my_q <- ms_load_product(
    my_ms_dir,
    prodname = 'discharge',
    site_codes = c('w7', 'GSWS07')
)
```



# Retrieve stream chemistry data for target sites


#### ms\_load\_product    *chemistry*
Now that we have discharge, we will use `ms_load_product` again, but for nitrate-N data. As we know from searching the variable catalog, the code for nitrate-N is 'NO3_N'

```{r ms-chem}
my_chem <- ms_load_product(
    my_ms_dir,
    prodname = 'stream_chemistry',
    filter_vars = 'NO3_N',
    site_codes = c('w7', 'GSWS07')
)

head(my_chem)
```


# Calculate daily flux*

*see `ms_calc_flux_rsfme` for calculating cumulative monthly/annual flux (in development at the time of this writing)


#### ms\_calc\_flux


Use `ms_calc_flux` to calculate daily nitrate-N flux from discharge and concentration datasets. 

```{r}
?ms_calc_flux
```

We can plug in our discharge and chemistry data directly. 

```{r ms-flux}
my_flux <- ms_calc_flux(
    chemistry = my_chem,
    q = my_q,
    q_type = 'discharge'
)

head(my_flux)
```

From the documentation of `ms_calc_flux` we can see that flux units are `kg/ha/T`, where T is the sampling interval. This is desirable because we are comparing between two very different watersheds and it is usually appropriate to scale by their areas. If you're interested in the unscaled flux, see 'ms\_undo\_scale\_flux\_by\_area'.

#### ms\_synchronize\_timestep

Macrosheds core time-series data are interpolated like so:
 + discharge: linear interpolation, gaps of up to 3 days
 + stream chemistry: linear interpolation, gaps of up to 15 days
 + precipitation chemistry (concentration): next-observation-carried-backward, gaps of up to 45 days
 + precipitation depth: 0-interpolation (unless special case), gaps of up to 45 days
 
If you'd like to modify these thresholds or use different techniques, you may:
 1. filter interpolated values from our datasets by removing records with `ms_status` of 1.
 2. increase our interpolation thresholds. For this, see `ms_synchronize_timestep`.
 3. specify interpolation methods via `ms_synchronize_timestep`

```{r ms-sync, message = FALSE}
my_chem2 <- ms_synchronize_timestep(
    my_chem,
    desired_interval = '1 day',
    interpolate_limit = 40
)
my_flux2 <- ms_calc_flux(
    chemistry = my_chem2,
    q = my_q,
    q_type = 'discharge'
)

head(my_flux)
```

# Results

We have now used the `macrosheds` package to retrieve discharge and stream nitrate-N data, and calculate daily flux for two sites on the east and west coasts of the United States with > 60 years of data. let's plot it!

Note: `macrosheds::ms_calc_flux_rsfme` will produce much more robust monthly and annual flux estimates. 
This function is in development, so check back. 

```{r ms-explore}
my_annual_mean_flux <- my_flux2 %>%
    mutate(year = as.numeric(format(as.Date(datetime), format='%Y'))) %>%
    group_by(year, site_code) %>%
    summarize(
        mean_flux = sum(val, na.rm = TRUE),
        n = n(),
        .groups = 'drop',
    ) %>%
    filter(n > 330)

ggplot(data=my_annual_mean_flux, aes(x=year, y=mean_flux, group=site_code)) +
    geom_line(aes(color=site_code), lwd = 2)+
    geom_point() +
    scale_color_manual(
      values=c('#E69F00', '#56B4E9'),
      name = 'Site'
    ) +
    ggtitle(
      label = 'Mean Annual Nitrate-N Flux',
      subtitle = 'Hubbard Brook (w7) and HJ Andrews (GSWS07), 1970-2020'
    ) +
    xlab('Year') +
    ylab('Nitrate-N Flux (kg/ha/day)') +
    theme_minimal() +
    theme(
      axis.text = element_text(size = 16),
      axis.title = element_text(size = 20),
      plot.title = element_text(size = 24),
      plot.subtitle = element_text(size = 22),
      legend.title = element_text(size = 21),
      legend.text = element_text(size = 20),
    ) 
  
```
