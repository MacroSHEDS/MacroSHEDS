---
title: "Precipitation Interpolation 2"
author: Spencer Rhea, Weston Slaughter, Mike Vlah
subtitle: Using the `macrosheds` package to interpolate rain gauge measurments to a 
output:
    html_document:
      toc: true 
      theme: united
      highlight: zenburn
      df_print: kable
editor_options: 
  chunk_output_type: console
---



This walkthought is intended for someone with a basic understanding of hydrology 
who whats to calculate basin average precipitation from a few rain gaues in or near
a watershed. We recomend looking at one of our other walkthroughs to get an understanding of how
to use the MacroSheds dataset in conjuction with the package.


# Install and explore the `macrosheds` package


To use the `macrosheds` package, you must first **make sure you have the `macrosheds` package on your computer, built, and installed in R**. Currently, the package is only available via github. If you have not already, you can install the `macrosheds` package as follows: 

```{r ms-install, eval = FALSE}
# install.packages('devtools') #you may need to install devtools too

devtools::install_github("https://github.com/MacroSHEDS/macrosheds")
```

Now, that we have the `macrosheds` package,  we load it into our library, along with other packages we will be using in this walkthrough. 

```{r setup-library, message = FALSE}
   
library(rnoaa)
library(sf)
library(nhdplusTools)
library(lubridate)
library(macrosheds)
library(ggplot2)
library(tidyverse)

```



This is a helper function used to search NOAA's Global Historical Climate Network- Daily for gauges near a location 
```{r}
search_noaa_stations <- function(lat, long, noaa_sites, buffer_km, start_year, end_year) {
    
    # Site = an sf object with a minimum of the columns: site_code and geometry
    # noaa_sites = an sf object with NOAA site info, made above 
    # buffer_km = the maximum distance from a stream gauge that will be searched 
    #     for NOAA site
    # start_year = numeric of when NOAA data should start (set same as stream start date)
    # end_year = numeric of when NOAA data should have data through (set same as stream end date)
    
    site <- tibble(lat = lat, long = long) %>%
        sf::st_as_sf(coords = c('long', 'lat'), crs = 4326) 
    
    buffer_m <- buffer_km*1000
    site_buf <- site %>%
        st_buffer(buffer_m)
    
    near_noaa <- st_filter(noaa_station_sf, site_buf)
    
    
    near_noaa_time <- near_noaa %>%
        filter(first_year <= start_year,
               last_year >= end_year)
    
    if(nrow(near_noaa_time) == 0){
        print(paste0('No station was found within ', buffer_km, ' km of site: ', site$site_code))
        return(list(data = tibble(),
                    relation = tibble(site_code = site$site_code,
                                      NOAA_id = NA,
                                      distance_km = NA)))
    }
    
    
    near_noaa_time <- near_noaa_time %>%
        mutate(distance = as.numeric(st_distance(geometry, site$geometry)))

    return(near_noaa_time)
}

download_clean_noaa_data <- function(noaa_ids) {
    
    noaa_data <- rnoaa::ghcnd(stationid = noaa_ids)
    
    col_names <- names(noaa_data)
    
    col_names[5:128] <- paste0(substr(col_names[5:128], 0, 5), '_', substr(col_names[5:128], 6, 7))
    
    colnames(noaa_data) <- col_names
    
    noaa_data_clean <- noaa_data %>%
        filter(element %in% c('TMAX', 'TMIN', 'PRCP'))
    
    noaa_data_clean_VALUE <- noaa_data_clean %>%
        select(id, year, month, element, grep('VALUE', col_names[5:128], value = T)) %>%
        pivot_longer(cols = grep('VALUE', col_names[5:128], value = T), values_to = 'VALUE') %>%
        mutate(day = str_split_fixed(name, '_', n = Inf)[,2]) %>%
        select(-name)
    
    noaa_data_clean_MFLAG <- noaa_data_clean %>%
        select(id, year, month, element, grep('MFLAG', col_names[5:128], value = T)) %>%
        pivot_longer(cols = grep('MFLAG', col_names[5:128], value = T), values_to = 'MFLAG') %>%
        mutate(day = str_split_fixed(name, '_', n = Inf)[,2]) %>%
        select(-name)
    
    noaa_data_clean_QFLAG <- noaa_data_clean %>%
        select(id, year, month, element, grep('QFLAG', col_names[5:128], value = T)) %>%
        pivot_longer(cols = grep('QFLAG', col_names[5:128], value = T), values_to = 'QFLAG') %>%
        mutate(day = str_split_fixed(name, '_', n = Inf)[,2]) %>%
        select(-name)
    
    noaa_data_clean_SFLAG <- noaa_data_clean %>%
        select(id, year, month, element, grep('SFLAG', col_names[5:128], value = T)) %>%
        pivot_longer(cols = grep('SFLAG', col_names[5:128], value = T), values_to = 'SFLAG') %>%
        mutate(day = str_split_fixed(name, '_', n = Inf)[,2]) %>%
        select(-name)
    
    all_noaa <- full_join(noaa_data_clean_VALUE, noaa_data_clean_MFLAG, by = c('id', 'year', 'month', 'day', 'element')) %>%
        full_join(., noaa_data_clean_QFLAG, by = c('id', 'year', 'month', 'day', 'element')) %>%
        full_join(., noaa_data_clean_SFLAG, by = c('id', 'year', 'month', 'day', 'element')) %>%
        filter(!is.na(VALUE)) %>%
        mutate(date = lubridate::ymd(paste0(year, '-', month, '-', day))) %>%
        mutate(VALUE = VALUE/10) %>%
        select(NOAA_id = id, date, element, VALUE, MFLAG, QFLAG, SFLAG) 
    
    return(all_noaa)
}
```

We need the file that has the location of all gauges in the NOAA database, so we'll 
use the `rnoaa::ghcnd_stations` function to pull that data and convert it to an sf
object so we can do geospatial filters on the data. 

```{r}
noaa_station <- rnoaa::ghcnd_stations()
# Only want sites that have temperature measurements
noaa_station_all_vars <- noaa_station %>%
    filter(element %in% c('PRCP'))

# Conver to sf object
noaa_station_sf <- noaa_station %>% 
    filter(id %in% !!unique(noaa_station_all_vars$id)) %>%
    distinct(id, .keep_all = T) %>% 
    sf::st_as_sf(., coords = c('longitude', 'latitude'), crs = 4326)
```

Now we'll search for station 30km from the center of the Poudre watershed
```{r}
near_stations <- search_noaa_stations(lat = 40.694473, long = -105.499921,
                                      noaa_sites = noaa_station_sf, buffer_km = 30,
                                      start_year = 2000, 2018)
```

Great there are quite a few gauges! Now we'll download the precipitation data for these stations.
This function will download noaa precipitation (PRCP), daily maximum (TMAX), and 
daily minimum (TMIN) temperature). NOAA provides this data in units of tenths of mm
and tenths of degrees. The function will convert these to mm and degrees C
```{r}
noaa_precip_data <- download_clean_noaa_data(noaa_ids = near_stations$id)
```

Precipitation data needs to be in the MacroSheds format to use the ms_calc_watershed_precip
function. This format is a table with the columns:
site_code = code for gauge,
datetime = datetime of the observation 
var = variable observed 
val = value of observation 
ms_status = 0 to indicate no issue, 1 to indicate possible issue 
ms_interp = 0 to indicate the value was measured, 1 to
   indicate the value is interpolated from surrounding values 
val_err = uncertainty unknown with observation, can set to 0 is unknown 

```{r}
ms_noaa_precip_data <- noaa_precip_data %>%
    filter(element == 'PRCP') %>%
    select(site_code = NOAA_id,
           datetime = date,
           var = element,
           val = VALUE) %>%
    mutate(ms_status = 0,
           ms_interp = 0,
           val_err= 0)  %>%
    mutate(var = 'IS_precipitation') %>%
    filter(year(datetime) == 2014)

# Check to make sure the precipitation records are mostly complete for 2014
complete_records <- ms_noaa_precip_data %>% 
    group_by(site_code) %>% 
    summarise(n = n()) %>%
    # Filter out any sites with more than 10 % of the record missing 
    filter(n >= 329) %>%
    pull(site_code)

ms_noaa_precip_data <- ms_noaa_precip_data %>%
    filter(site_code %in% !!complete_records)

gauges_with_data <- unique(ms_noaa_precip_data$site_code)
```

We also need an sf object in the MacroSheds format with the locations of precipitation 
gauges. We can use the NOAA site data and convert it to MacroSheds format.

```{r}
ms_near_stations <- near_stations %>%
    select(site_code = id,
           geometry) %>%
    filter(site_code %in% !!gauges_with_data)
```

The last piece we need is a watershed boundary! The Poudre watersheds is included in
MacroSheds as an example but see the data documentation for how to retrieve a watersheds
using nhdplusTools. 
```{r}
print(poudre_ws)
mapview::mapview(poudre_ws)
```

```{r}
?poudre_ws
```


Now we have everything we need! Let's put into the `ms_calc_watershed_precip` function
```{r}
ms_calc_watershed_precip(precip = ms_noaa_precip_data,
                         ws_boundary = poudre_ws,
                         precip_gauge = ms_near_stations,
                         parallel = TRUE,
                         maxcores = Inf,
                         out_path = 'example',
                         elevation_agnostic = TRUE,
                         verbose = TRUE)
```

Let's look at the data!
```{r}
pourdre_precip <- feather::read_feather('example/precipitation__ms900/poudre_river.feather')
```

Let's compare the basin average vlaues to the individual gauges 
```{r}
ms_noaa_precip_data_wide <- ms_noaa_precip_data %>%
    select(site_code, datetime, val) %>%
    pivot_wider(names_from = 'site_code', values_from = 'val')

precip_compare <- pourdre_precip %>%
    full_join(ms_noaa_precip_data_wide, by = 'datetime')

ggplot(precip_compare, aes(val, US1COLR0250)) +
    geom_point() +
    geom_abline()
```

```{r}
ggplot(precip_compare, aes(val, US1COLR0252)) +
    geom_point() +
    geom_abline()
```

```{r}
ggplot(precip_compare, aes(val, US1COLR0329)) +
    geom_point() +
    geom_abline()
```

```{r}
ggplot(precip_compare, aes(val, US1COLR0546)) +
    geom_point() +
    geom_abline()
```

```{r}
ggplot(precip_compare, aes(val, USC00051060)) +
    geom_point() +
    geom_abline()
```

```{r}
ggplot(precip_compare, aes(val, USC00054135)) +
    geom_point() +
    geom_abline()
```

```{r}
ggplot(precip_compare, aes(val, USC00057296)) +
    geom_point() +
    geom_abline()
```

```{r}
ggplot(precip_compare, aes(val, USS0005J06S)) +
    geom_point() +
    geom_abline()
```

```{r}
US1COLR0250 <- summary(lm(val~US1COLR0250, precip_compare))[["r.squared"]]
US1COLR0252 <- summary(lm(val~US1COLR0252, precip_compare))[["r.squared"]]
US1COLR0329 <- summary(lm(val~US1COLR0329, precip_compare))[["r.squared"]]
US1COLR0546 <- summary(lm(val~US1COLR0546, precip_compare))[["r.squared"]]
USC00051060 <- summary(lm(val~USC00051060, precip_compare))[["r.squared"]]
USC00054135 <- summary(lm(val~USC00054135, precip_compare))[["r.squared"]]
USC00057296 <- summary(lm(val~USC00057296, precip_compare))[["r.squared"]]
USS0005J06S <- summary(lm(val~USS0005J06S, precip_compare))[["r.squared"]]
```

```{r}
r_2 <- tibble(US1COLR0250 = US1COLR0250,
       US1COLR0252 = US1COLR0252,
       US1COLR0329 = US1COLR0329,
       US1COLR0546 = US1COLR0546,
       USC00051060 = USC00051060,
       USC00054135 = USC00054135,
       USC00057296 = USC00057296,
       USS0005J06S = USS0005J06S) %>%
    pivot_longer(cols = everything(), names_to = 'site_code', values_to = 'r2')

ms_near_stations_r <- ms_near_stations %>%
    left_join(., r_2)
```

```{r}
ms_calc_watershed_precip(precip = ms_noaa_precip_data,
                         ws_boundary = poudre_ws,
                         precip_gauge = ms_near_stations,
                         parallel = TRUE,
                         maxcores = Inf,
                         out_path = 'example_2',
                         elevation_agnostic = F,
                         verbose = TRUE)

pourdre_precip_elev <- feather::read_feather('example_2/precipitation__ms900/poudre_river.feather')
precip_compare <- pourdre_precip %>%
    full_join(ms_noaa_precip_data_wide, by = 'datetime')

US1COLR0250 <- summary(lm(val~US1COLR0250, precip_compare))[["r.squared"]]
US1COLR0252 <- summary(lm(val~US1COLR0252, precip_compare))[["r.squared"]]
US1COLR0329 <- summary(lm(val~US1COLR0329, precip_compare))[["r.squared"]]
US1COLR0546 <- summary(lm(val~US1COLR0546, precip_compare))[["r.squared"]]
USC00051060 <- summary(lm(val~USC00051060, precip_compare))[["r.squared"]]
USC00054135 <- summary(lm(val~USC00054135, precip_compare))[["r.squared"]]
USC00057296 <- summary(lm(val~USC00057296, precip_compare))[["r.squared"]]
USS0005J06S <- summary(lm(val~USS0005J06S, precip_compare))[["r.squared"]]

r_2 <- tibble(US1COLR0250 = US1COLR0250,
       US1COLR0252 = US1COLR0252,
       US1COLR0329 = US1COLR0329,
       US1COLR0546 = US1COLR0546,
       USC00051060 = USC00051060,
       USC00054135 = USC00054135,
       USC00057296 = USC00057296,
       USS0005J06S = USS0005J06S) %>%
    pivot_longer(cols = everything(), names_to = 'site_code', values_to = 'r2')

ms_near_stations_r <- ms_near_stations %>%
    left_join(., r_2)

mapview::mapview(ms_near_stations_r, zcol = 'r2') + poudre_ws


look <- pourdre_precip %>%
    rename(no_elev = val) %>%
    full_join(pourdre_precip_elev)

ggplot(look, aes(no_elev, val)) + geom_point()
```

